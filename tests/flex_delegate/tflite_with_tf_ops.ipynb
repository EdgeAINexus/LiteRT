{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/8vyp0M3z6pERv/t6l3S+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google-ai-edge/LiteRT/blob/main/tests/flex_delegate/tflite_with_tf_ops.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DDaAex5Q7u-"
      },
      "source": [
        "##### Copyright 2024 The AI Edge LiteRT Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "W1dWWdNHQ9L0"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Conversion\n",
        "\n",
        "Model conversion with `SELECT_TF_OPS`.\n",
        "This example shows a way to convert TF model with using TF ops."
      ],
      "metadata": {
        "id": "pxCw8RTg6V-K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PF-0MrUT1k_r",
        "outputId": "c427c0cc-afaf-4e54-9264-f00c67861365",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1.1752012], shape=(1,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "@tf.function(\n",
        "  input_signature=[tf.TensorSpec(shape=[1], dtype=tf.float32)])\n",
        "def model(x):\n",
        "  return tf.sinh(x)\n",
        "\n",
        "print(model([1.0]))\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([model.get_concrete_function()], model)\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS    # enable TensorFlow ops.\n",
        "]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('model_sinh.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the model with tf.lite\n",
        "\n",
        "Run the converted `model_sinh.tflite` model with `tf.lite.Interpreter`"
      ],
      "metadata": {
        "id": "c0OzB3gm3GDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "interpreter = tf.lite.Interpreter('model_sinh.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "output_details = interpreter.get_output_details()[0]\n",
        "input_details = interpreter.get_input_details()[0]\n",
        "input_data = tf.constant(1.0, shape=[1])\n",
        "interpreter.set_tensor(input_details['index'], input_data)\n",
        "interpreter.invoke()\n",
        "res = interpreter.get_tensor(output_details['index'])\n",
        "print(res)"
      ],
      "metadata": {
        "id": "miLWPKdb3NWi",
        "outputId": "c7d1e230-ee7c-4894-d738-624055fdff6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.1752012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the model with tflite_runtime\n",
        "\n",
        "\n",
        "Run the converted `model_sinh.tflite` model with `tflite_runtime.interpreter.Interpreter`\n",
        "This script doesn't use `tf` package. It uses smaller `tflite_runtime` package with `numpy` package."
      ],
      "metadata": {
        "id": "80zYvE4f4yQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install tflite_runtime PIP package\n",
        "!pip install tflite_runtime"
      ],
      "metadata": {
        "id": "E6JBM8pg5Qap",
        "outputId": "2873a500-37b7-4467-d3f7-019ebac8749b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflite_runtime\n",
            "  Downloading tflite_runtime-2.14.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.10/dist-packages (from tflite_runtime) (1.26.4)\n",
            "Downloading tflite_runtime-2.14.0-cp310-cp310-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tflite_runtime\n",
            "Successfully installed tflite_runtime-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tflite_runtime.interpreter as tflite\n",
        "import numpy as np\n",
        "\n",
        "interpreter = tflite.Interpreter('model_sinh.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "output_details = interpreter.get_output_details()[0]\n",
        "input_details = interpreter.get_input_details()[0]\n",
        "input_data = np.array([1.0], dtype=np.float32)\n",
        "interpreter.set_tensor(input_details['index'], input_data)\n",
        "interpreter.invoke()\n",
        "res = interpreter.get_tensor(output_details['index'])\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30FR4xyq4-vF",
        "outputId": "2937062f-3b89-4be8-fe0e-c05d0e334a4a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.1752012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the model with LiteRT\n",
        "\n",
        "\n",
        "Run the converted `model_sinh.tflite` model with `ai_edge_litert.interpreter.Interpreter`."
      ],
      "metadata": {
        "id": "1S9iAZw6rtl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install LiteRT package\n",
        "!pip install ai-edge-litert"
      ],
      "metadata": {
        "outputId": "cd46c627-3df6-4964-d2fa-40b3743d98d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbE4hGmertl-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference with LiteRT\n",
        "from ai_edge_litert.interpreter import Interpreter\n",
        "import numpy as np\n",
        "\n",
        "interpreter = Interpreter('model_sinh.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "output_details = interpreter.get_output_details()[0]\n",
        "input_details = interpreter.get_input_details()[0]\n",
        "input_data = np.array([1.0], dtype=np.float32)\n",
        "interpreter.set_tensor(input_details['index'], input_data)\n",
        "interpreter.invoke()\n",
        "res = interpreter.get_tensor(output_details['index'])\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b744a7-9284-41e1-c38c-31e0834518d2",
        "id": "5n-5K646rtl_"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.1752012]\n"
          ]
        }
      ]
    }
  ]
}